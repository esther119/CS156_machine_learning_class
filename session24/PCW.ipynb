{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/Users/swimmingcircle/cs156_code/session24/speaker.txt', 'r').read()\n",
    "\n",
    "symbols = {'A':0, 'o':1, 'e':2, 't':3, 'p':4, 'g':5, 'k':6}\n",
    "nums = np.array([symbols[i] for i in file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 141, 1: 188, 5: 121, 0: 176, 4: 167, 3: 168, 6: 39})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_prob_dist(nums):\n",
    "    '''Initial prob distribution'''\n",
    "    max_num = nums.max()\n",
    "    length = len(nums)\n",
    "    counter=collections.Counter(nums)\n",
    "    dist = []\n",
    "    for i in range(max_num+1): \n",
    "        dist.append(counter[i]/length) \n",
    "    return dist \n",
    "initial_dist = initial_prob_dist(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(transitions):\n",
    "    '''\n",
    "    the following code takes a list such as\n",
    "    [1,1,2,6,8,5,5,7,8,8,1,1,4,5,5,0,0,0,1,1,4,4,5,1,3,3,4,5,4,1,1]\n",
    "    with states labeled as successive integers starting with 0\n",
    "    and returns a transition matrix, M,\n",
    "    where M[i][j] is the probability of transitioning from i to j\n",
    "    Resource: https://stackoverflow.com/questions/46657221/generating-markov-transition-matrix-in-python\n",
    "    '''\n",
    "\n",
    "    n = 1+ max(transitions) #number of states\n",
    "\n",
    "    M = [[0]*n for _ in range(n)]\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[1:]):\n",
    "        M[i][j] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M\n",
    "\n",
    "def print_matrix(m): \n",
    "    for row in m: \n",
    "        print(' '.join('{0:.2f}'.format(x) for x in row))\n",
    "    return None\n",
    "M = transition_matrix(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31 0.12 0.05 0.31 0.09 0.09 0.04\n",
      "0.15 0.28 0.09 0.06 0.31 0.06 0.04\n",
      "0.11 0.16 0.29 0.09 0.08 0.26 0.03\n",
      "0.27 0.11 0.09 0.36 0.08 0.05 0.04\n",
      "0.09 0.33 0.09 0.05 0.31 0.09 0.04\n",
      "0.07 0.12 0.29 0.11 0.12 0.25 0.06\n",
      "0.26 0.13 0.23 0.18 0.10 0.08 0.03\n"
     ]
    }
   ],
   "source": [
    "print_matrix(M)\n",
    "M = np.array(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The emission probabilities: are the maximum likelihood estimates of the letters in each column. \n",
    "- The transition probabilities: are obtained by counting the number of times each transition would be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            # Matrix Computation Steps\n",
    "            #                  ((1x2) . (1x2))      *     (1)\n",
    "            #                        (1)            *     (1)\n",
    "            alpha[t, j] = alpha[t - 1] @ a[:, j] * b[j, V[t]]\n",
    " \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]) @ a[j, :]\n",
    " \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    "\n",
    "    for n in range(n_iter):\n",
    "        ###estimation step\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    "\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            # joint probab of observed data up to time t @ transition prob * emisssion prob as t+1 @\n",
    "            # joint probab of observed data from time t+1\n",
    "            denominator = (alpha[t, :].T @ a * b[:, V[t + 1]].T) @ beta[t + 1, :]\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    "\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        ### maximization step\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    "\n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    "\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31 0.12 0.05 0.31 0.09 0.09 0.04\n",
      "0.15 0.28 0.09 0.06 0.31 0.06 0.04\n",
      "0.11 0.16 0.29 0.09 0.08 0.26 0.03\n",
      "0.27 0.11 0.09 0.36 0.08 0.05 0.04\n",
      "0.09 0.33 0.09 0.05 0.31 0.09 0.04\n",
      "0.07 0.12 0.29 0.11 0.12 0.25 0.06\n",
      "0.26 0.13 0.23 0.18 0.10 0.08 0.03\n"
     ]
    }
   ],
   "source": [
    "print_matrix(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0h/xyv81g2n7sj6zr0c9cw30gkc0000gn/T/ipykernel_51084/2676471524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0ma_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaum_welch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_distribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Custom model A is \\n{a_model} \\n \\nCustom model B is \\n{b_model}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0h/xyv81g2n7sj6zr0c9cw30gkc0000gn/T/ipykernel_51084/1947021012.py\u001b[0m in \u001b[0;36mbaum_welch\u001b[0;34m(V, a, b, initial_distribution, n_iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m###estimation step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0h/xyv81g2n7sj6zr0c9cw30gkc0000gn/T/ipykernel_51084/1976711495.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(V, a, b, initial_distribution)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_distribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_distribution\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7,) (3,) "
     ]
    }
   ],
   "source": [
    "# # Transition Probabilities\n",
    "a = np.ones((3, 3))\n",
    "a = a / np.sum(a, axis=1)\n",
    "\n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5, 7, 9, 11, 13), (2, 4, 6, 8 , 10, 12, 14),(2, 4, 6, 8 , 10, 12, 14) ))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array(initial_dist)\n",
    "\n",
    "n_iter = 100\n",
    "a_model, b_model = baum_welch(nums.copy(), a.copy(), b.copy(), initial_distribution.copy(), n_iter=n_iter)\n",
    "print(f'Custom model A is \\n{a_model} \\n \\nCustom model B is \\n{b_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_distribution * b[:, V[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.176, 0.188, 0.141, 0.168, 0.167, 0.121, 0.039])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10204082, 0.10714286, 0.10714286])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:, nums[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tuple must have size 2, but has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0h/xyv81g2n7sj6zr0c9cw30gkc0000gn/T/ipykernel_51084/994806230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Tuple must have size 2, but has size 3"
     ]
    }
   ],
   "source": [
    "np.array((1, 3, 5), (2, 4, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11111111, 0.33333333, 0.55555556],\n",
       "       [0.16666667, 0.33333333, 0.5       ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99243258 0.00756742]\n",
      " [0.76214952 0.23785048]]\n",
      "[[4.95835849e-01 5.04164151e-01]\n",
      " [6.54703366e-08 9.99999935e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Observations (1 = Late, 0 = On Time)\n",
    "obs = np.array([1,1,0,0,1,0,1])\n",
    "\n",
    "# Initializations\n",
    "# Make these values sensible\n",
    "x0 = np.array([0.5, 0.5])\n",
    "\n",
    "# Transition matrix A_ij: this is the probability that we end up in state i, given we were in state j\n",
    "A = np.array([[0.9, 0.1],[0.9, 0.1]])\n",
    "\n",
    "# Emission Matrix B_jk: this is the probability\n",
    "B = np.array([[0.5, 0.5],[0.5, 0.5]])\n",
    "\n",
    "# Forward pass to calculate the alphas\n",
    "def calc_alpha(x0, A, B, y):\n",
    "    #Initialize\n",
    "    n = len(x0)\n",
    "    N = len(y)\n",
    "    alpha = np.zeros((n,N))\n",
    "    alpha[:,0] = x0 * B[:,y[0]] #t = 0, the value of hidden state given the observed state \n",
    "    for t in range(1,N):\n",
    "        alpha[:,t] = (A.T @ alpha[:,t-1]) * B[:,y[t]]\n",
    "    return alpha\n",
    "\n",
    "# Backward pass to calculate the betas\n",
    "def calc_beta(x0, A, B, y):\n",
    "    #Initialize\n",
    "    n = len(x0)\n",
    "    N = len(y)\n",
    "    beta = np.zeros((n,N))\n",
    "    beta[:,N-1] = np.ones(n)\n",
    "    for t in range(N-1,0,-1):\n",
    "        beta[:,t-1] = A @ (beta[:,t] * B[:,y[t]])\n",
    "    return beta\n",
    "\n",
    "# E step\n",
    "def e_step(x0, A, B, y):\n",
    "    n = len(x0)\n",
    "    N = len(y)\n",
    "    alpha = calc_alpha(x0, A, B, y)\n",
    "    beta = calc_beta(x0, A, B, y)\n",
    "    # Marginal probability of all observations\n",
    "    p_y = sum(alpha[:,-1])\n",
    "    gamma = (alpha * beta) / p_y\n",
    "    xi = alpha[:,np.newaxis,0:-1] * A[:,:,np.newaxis] * B[np.newaxis,0:,y[1:]] * beta[np.newaxis,0:,1:] / p_y\n",
    "    return gamma, xi\n",
    "\n",
    "# M step\n",
    "def m_step(gamma, xi, y):\n",
    "    symbols = np.unique(y)\n",
    "    A_new = np.sum(xi, axis = 2)/np.sum(xi, axis = (1,2))[:,np.newaxis]\n",
    "    B_new = np.zeros(B.shape)\n",
    "    for k in range(0,len(symbols)):\n",
    "        B_new[:,k] = np.sum(gamma[:,y == symbols[k]], axis = 1) / np.sum(gamma, axis = 1)\n",
    "    return A_new, B_new\n",
    "\n",
    "# Run the EM algorithm\n",
    "for steps in range(0,15):\n",
    "    [gamma, xi] = e_step(x0, A, B, obs)\n",
    "    [A,B] = m_step(gamma, xi, obs)\n",
    "    \n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
