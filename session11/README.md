## 6.2 Maximum Likelihood Learning

## Study Guide

After you have completed the reading, you should be able to:

- Explain in your own words how a likelihood function is different from a probability distribution.
- Explain the central idea behind the maximum likelihood learning.
- Explain why is it useful to know the parameters of your model that maximize the likelihood?

## Pre-class work

### 1. Maximum Likelihood Estimation of a Bernoulli Distribution

Suppose we have a random sample X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub> where:

- X<sub>i</sub> = 0 if a randomly selected student does not eat meat, and
- X<sub>i</sub> = 1 if a randomly selected student does eat meat.

Assuming that the X<sub>i</sub> are independent Bernoulli random variables with unknown parameter p, derive the maximum likelihood estimator of p, the proportion of students who eat meat.

### 2. Maximum Likelihood Estimation for a Normal Distribution

Derive the maximum likelihood estimate for a group of observations that is normally distributed, but with unknown mean and variance. How does the maximum likelihood estimate compare to the standard estimates of an unknown mean and variance?

For these questions, make sure your answers are uploaded to your personal repository <b>before</b> the start of class
